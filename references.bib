@ARTICLE{Ben-Taieb2021-bn,
  title     = "Hierarchical probabilistic forecasting of electricity demand with
               smart meter data",
  author    = "Ben Taieb, Souhaib and Taylor, James W and Hyndman, Rob J",
  journal   = "Journal of the American Statistical Association",
  publisher = "Informa UK Limited",
  volume    =  116,
  number    =  533,
  pages     = "27--43",
  month     =  "2~" # jan,
  year      =  2021,
  url       = "https://www.tandfonline.com/doi/full/10.1080/01621459.2020.1736081",
  doi       = "10.1080/01621459.2020.1736081",
  language  = "en"
}

@ARTICLE{Shang2017-ux,
  title     = "Grouped functional time series forecasting: An application to
               age-specific mortality rates",
  author    = "Shang, Han Lin and Hyndman, Rob J",
  journal   = "Journal of computational and graphical statistics: a joint
               publication of American Statistical Association, Institute of
               Mathematical Statistics, Interface Foundation of North America",
  publisher = "Informa UK Limited",
  volume    =  26,
  number    =  2,
  pages     = "330--343",
  abstract  = "Age-specific mortality rates are often disaggregated by different
               attributes, such as sex, state, and ethnicity. Forecasting
               age-specific mortality rates at the national and sub-national
               levels plays an important role in developing social policy.
               However, independent forecasts at the sub-national levels may not
               add up to the forecasts at the national level. To address this
               issue, we consider reconciling forecasts of age-specific
               mortality rates, extending the methods of Hyndman et al. in 2011
               to functional time series, where age is considered as a
               continuum. The grouped functional time series methods are used to
               produce point forecasts of mortality rates that are aggregated
               appropriately across different disaggregation factors. For
               evaluating forecast uncertainty, we propose a bootstrap method
               for reconciling interval forecasts. Using the regional
               age-specific mortality rates in Japan, obtained from the Japanese
               Mortality Database, we investigate the one- to ten-step-ahead
               point and interval forecast accuracies between the independent
               and grouped functional time series forecasting methods. The
               proposed methods are shown to be useful for reconciling forecasts
               of age-specific mortality rates at the national and sub-national
               levels. They also enjoy improved forecast accuracy averaged over
               different disaggregation factors. Supplementary materials for the
               article are available online.",
  month     =  "3~" # apr,
  year      =  2017,
  url       = "http://dx.doi.org/10.1080/10618600.2016.1237877",
  doi       = "10.1080/10618600.2016.1237877",
  language  = "en"
}

@ARTICLE{Jeon2019-wm,
  title     = "Probabilistic forecast reconciliation with applications to wind
               power and electric load",
  author    = "Jeon, Jooyoung and Panagiotelis, Anastasios and Petropoulos,
               Fotios",
  journal   = "European journal of operational research",
  publisher = "Elsevier BV",
  volume    =  279,
  number    =  2,
  pages     = "364--379",
  month     =  dec,
  year      =  2019,
  url       = "http://dx.doi.org/10.1016/j.ejor.2019.05.020",
  doi       = "10.1016/j.ejor.2019.05.020",
  language  = "en"
}

@ARTICLE{Rothman2009-yf,
  title     = "Generalized Thresholding of Large Covariance Matrices",
  author    = "Rothman, Adam J and Levina, Elizaveta and Zhu, Ji",
  journal   = "Journal of the American Statistical Association",
  publisher = "Informa UK Limited",
  volume    =  104,
  number    =  485,
  pages     = "177--186",
  month     =  mar,
  year      =  2009,
  url       = "http://dx.doi.org/10.1198/jasa.2009.0101",
  doi       = "10.1198/jasa.2009.0101"
}

@ARTICLE{Bickel2008-nh,
  title     = "Covariance regularization by thresholding",
  author    = "Bickel, Peter J and Levina, Elizaveta",
  journal   = "Annals of statistics",
  publisher = "Institute of Mathematical Statistics",
  volume    =  36,
  number    =  6,
  pages     = "2577--2604",
  month     =  "1~" # dec,
  year      =  2008,
  url       = "http://dx.doi.org/10.1214/08-AOS600",
  doi       = "10.1214/08-aos600"
}

@ARTICLE{Cai2011-jf,
  title     = "Adaptive Thresholding for Sparse Covariance Matrix Estimation",
  author    = "Cai, Tony and Liu, Weidong",
  journal   = "Journal of the American Statistical Association",
  publisher = "Informa UK Limited",
  volume    =  106,
  number    =  494,
  pages     = "672--684",
  month     =  jun,
  year      =  2011,
  url       = "http://dx.doi.org/10.1198/jasa.2011.tm10560",
  doi       = "10.1198/jasa.2011.tm10560"
}

@ARTICLE{Ledoit2020-xt,
  title     = "Analytical nonlinear shrinkage of large-dimensional covariance
               matrices",
  author    = "Ledoit, Olivier and Wolf, Michael",
  journal   = "Annals of statistics",
  publisher = "Institute of Mathematical Statistics",
  volume    =  48,
  number    =  5,
  pages     = "3043--3065",
  year      =  2020,
  url       = "http://dx.doi.org/10.1214/19-AOS1921",
  doi       = "10.1214/19-AOS1921"
}


@ARTICLE{Ledoit2012-ga,
  title    = "Nonlinear shrinkage estimation of large-dimensional covariance
              matrices",
  author   = "Ledoit, O and Wolf, M",
  journal  = "Annals of statistics",
  abstract = "Many statistical applications require an estimate of a covariance
              matrix and/or its inverse. When the matrix dimension is large
              compared to the sample size, which happens frequently, the sample
              covariance matrix is known to perform poorly and may suffer from
              ill-conditioning. There already exists an extensive literature
              concerning improved estimators in such situations. In the absence
              of further knowledge about the structure of the true covariance
              matrix, the most successful approach so far, arguably, has been
              shrinkage estimation. Shrinking the sample covariance matrix to a
              multiple of the identity, by taking a weighted average of the two,
              turns out to be equivalent to linearly shrinking the sample
              eigenvalues to their grand mean, while retaining the sample
              eigenvectors. Our paper extends this approach by considering
              nonlinear transformations of the sample eigenvalues. We show how
              to construct an estimator that is asymptotically equivalent to an
              oracle estimator suggested in previous work. As demonstrated in
              extensive Monte Carlo simulations, the resulting bona fide
              estimator can result in sizeable improvements over the sample
              covariance matrix and also over linear shrinkage.",
  year     =  2012,
  url      = "http://dx.doi.org/10.1214/12-AOS989",
  doi      = "10.1214/12-AOS989"
}


@MISC{Nixtla,
  title  = "Time Series Forecasting Software",
  author = "{Nixtla}",
  year   =  2025,
  url    = "https://www.nixtla.io/"
}

@PHDTHESIS{Gamakumara2020-ml,
  title     = "Probabilistic forecast reconciliation: Theory and applications",
  author    = "Gamakumara, P",
  publisher = "Monash University",
  year      =  2020,
  url       = "http://dx.doi.org/10.26180/5e4ca9d0c4b9d",
  doi       = "10.26180/5e4ca9d0c4b9d"
}

@ARTICLE{Hyndman2008-rf,
  title    = "Automatic time series forecasting: The forecast package for {R}",
  author   = "Hyndman, Rob J and Khandakar, Yeasmin",
  journal  = "Journal of Statistical Software",
  volume   =  27,
  pages    = "1--22",
  abstract = "Automatic forecasts of large numbers of univariate time series are
              often needed in business and other contexts. We describe two
              automatic forecasting algorithms that have been implemented in the
              forecast package for R. The first is based on innovations state
              space models that underly exponential smoothing methods. The
              second is a step-wise algorithm for forecasting with ARIMA models.
              The algorithms are applicable to both seasonal and non-seasonal
              data, and are compared and illustrated using four real time
              series. We also briefly describe some of the other functionality
              available in the forecast package.",
  month    =  "29~" # jul,
  year     =  2008,
  url      = "http://www.jstatsoft.org/v27/i03/",
  doi      = "10.18637/JSS.V027.I03"
}

@ARTICLE{Athanasopoulos2009-lp,
  title     = "Hierarchical forecasts for Australian domestic tourism",
  author    = "Athanasopoulos, George and Ahmed, Roman A and Hyndman, Rob J",
  journal   = "International journal of forecasting",
  publisher = "Elsevier BV",
  volume    =  25,
  number    =  1,
  pages     = "146--166",
  abstract  = "In this paper we explore the hierarchical nature of tourism
               demand time series and produce short-term forecasts for
               Australian domestic tourism. The data and forecasts are organized
               in a hierarchy based on disaggregating the data according to
               geographical regions and purposes of travel. We consider five
               approaches to hierarchical forecasting: two variations of the
               top-down approach, the bottom-up method, a newly proposed
               top-down approach where top-level forecasts are disaggregated
               according to the forecasted proportions of lower level series,
               and a recently proposed optimal combination approach. Our
               forecast performance evaluation shows that the top-down approach
               based on forecast proportions and the optimal combination method
               perform best for the tourism hierarchies we consider. By applying
               these methods, we produce detailed forecasts of the Australian
               domestic tourism market.",
  month     =  jan,
  year      =  2009,
  url       = "http://dx.doi.org/10.1016/j.ijforecast.2008.07.004",
  doi       = "10.1016/j.ijforecast.2008.07.004",
  language  = "en"
}

@ARTICLE{El-Gemayel2022-hx,
  title     = "United arab emirates: Technical assistance reportliquidity
               management and forecasting",
  author    = "El Gemayel, J and Lafarguette, R and Itd, K M and {others}",
  publisher = "International Monetary Fund",
  year      =  2022
}

@ARTICLE{Seaman2022-bb,
  title     = "Applicability of the {M5} to forecasting at Walmart",
  author    = "Seaman, Brian and Bowman, John",
  journal   = "International journal of forecasting",
  publisher = "Elsevier BV",
  volume    =  38,
  number    =  4,
  pages     = "1468--1472",
  month     =  oct,
  year      =  2022,
  url       = "http://dx.doi.org/10.1016/j.ijforecast.2021.06.002",
  doi       = "10.1016/j.ijforecast.2021.06.002",
  language  = "en"
}

@INCOLLECTION{Angam2025-od,
  title     = "Forecast reconciliation for vaccine supply chain optimization",
  author    = "Angam, Bhanu and Beretta, Alessandro and De Poorter, Eli and
               Duvinage, Matthieu and Peralta, Daniel",
  booktitle = "Communications in Computer and Information Science",
  publisher = "Springer Nature Switzerland",
  address   = "Cham",
  pages     = "101--118",
  series    = "Communications in computer and information science",
  year      =  2025,
  url       = "http://dx.doi.org/10.1007/978-3-031-74650-5_6",
  doi       = "10.1007/978-3-031-74650-5\_6",
  language  = "en"
}

@ARTICLE{Di-Modica2021-ad,
  title     = "Online forecast reconciliation in wind power prediction",
  author    = "Di Modica, Chiara and Pinson, Pierre and Ben Taieb, Souhaib",
  journal   = "Electric power systems research",
  publisher = "Elsevier BV",
  volume    =  190,
  number    =  106637,
  pages     =  106637,
  month     =  jan,
  year      =  2021,
  url       = "http://dx.doi.org/10.1016/j.epsr.2020.106637",
  doi       = "10.1016/j.epsr.2020.106637",
  language  = "en"
}

@ARTICLE{Li2019-vv,
  title     = "A forecast reconciliation approach to cause-of-death mortality
               modeling",
  author    = "Li, Han and Li, Hong and Lu, Yang and Panagiotelis, Anastasios",
  journal   = "Insurance, mathematics \& economics",
  publisher = "Elsevier BV",
  volume    =  86,
  pages     = "122--133",
  month     =  may,
  year      =  2019,
  url       = "http://dx.doi.org/10.1016/j.insmatheco.2019.02.011",
  doi       = "10.1016/j.insmatheco.2019.02.011",
  language  = "en"
}

@ARTICLE{Rockafellar2000-el,
  title   = "Optimization of conditional value-at-risk",
  author  = "Rockafellar, R T and Uryasev, S",
  journal = "Journal of risk",
  volume  =  2,
  pages   = "21--42",
  year    =  2000,
  url     = "https://www.risknet.de/fileadmin/eLibrary/Rockafellar-Conditional-Value-at-Risk.pdf"
}

@ARTICLE{Panagiotelis2021-ci,
  title     = "Forecast reconciliation: A geometric view with new insights on
               bias correction",
  author    = "Panagiotelis, Anastasios and Athanasopoulos, George and
               Gamakumara, Puwasala and Hyndman, Rob J",
  journal   = "International journal of forecasting",
  publisher = "Elsevier BV",
  volume    =  37,
  number    =  1,
  pages     = "343--359",
  month     =  jan,
  year      =  2021,
  url       = "http://dx.doi.org/10.1016/j.ijforecast.2020.06.004",
  doi       = "10.1016/j.ijforecast.2020.06.004",
  language  = "en"
}

@MISC{Basel-iii,
  title  = "Explanatory note on the minimum capital requirements for market risk",
  author = "{Basel Committee on Banking Supervision}",
  year   =  2019,
  url    = "https://www.bis.org/bcbs/publ/d457_note.pdf"
}

@ARTICLE{Gneiting2011-km,
  title     = "Making and evaluating point forecasts",
  author    = "Gneiting, Tilmann",
  journal   = "Journal of the American Statistical Association",
  publisher = "Informa UK Limited",
  volume    =  106,
  number    =  494,
  pages     = "746--762",
  month     =  jun,
  year      =  2011,
  url       = "http://dx.doi.org/10.1198/jasa.2011.r10138",
  doi       = "10.1198/jasa.2011.r10138",
  language  = "en"
}

@ARTICLE{Fissler2015-uu,
  title         = "Expected Shortfall is jointly elicitable with Value at Risk -
                   Implications for backtesting",
  author        = "Fissler, Tobias and Ziegel, Johanna F and Gneiting, Tilmann",
  journal       = "arXiv [q-fin.RM]",
  abstract      = "In this note, we comment on the relevance of elicitability
                   for backtesting risk measure estimates. In particular, we
                   propose the use of Diebold-Mariano tests, and show how they
                   can be implemented for Expected Shortfall (ES), based on the
                   recent result of Fissler and Ziegel (2015) that ES is jointly
                   elicitable with Value at Risk.",
  month         =  "1~" # jul,
  year          =  2015,
  url           = "http://arxiv.org/abs/1507.00244",
  archivePrefix = "arXiv",
  primaryClass  = "q-fin.RM"
}

@ARTICLE{Yamai2005-me,
  title     = "Value-at-risk versus expected shortfall: A practical perspective",
  author    = "Yamai, Yasuhiro and Yoshiba, Toshinao",
  journal   = "Journal of banking \& finance",
  publisher = "Elsevier BV",
  volume    =  29,
  number    =  4,
  pages     = "997--1015",
  abstract  = "Value-at-Risk (VaR) has become a standard risk measure for
               financial risk management. However, many authors claim that there
               are several conceptual problems with VaR. Among these problems,
               an important one is that VaR disregards any loss beyond the VaR
               level. We call this problem the “tail risk”. In this paper, we
               illustrate how the tail risk of VaR can cause serious problems in
               certain cases, cases in which expected shortfall can serve more
               aptly in its place. We discuss two cases: concentrated credit
               portfolio and foreign exchange rates under market stress. We show
               that expected shortfall requires a larger sample size than VaR to
               provide the same level of accuracy.",
  month     =  apr,
  year      =  2005,
  url       = "http://dx.doi.org/10.1016/j.jbankfin.2004.08.010",
  doi       = "10.1016/j.jbankfin.2004.08.010",
  language  = "en"
}

@MISC{ReconCov,
  title   = "{ReconCov} {R} package",
  author  = "Su, Vincent",
  year    =  2025,
  url     = "https://github.com/lordtahdus/ReconCov",
  version = "beta"
}

@INCOLLECTION{Van_Erven2015-nx,
  title     = "Game-theoretically optimal reconciliation of contemporaneous
               hierarchical time series forecasts",
  author    = "van Erven, Tim and Cugliari, Jairo",
  booktitle = "Modeling and Stochastic Learning for Forecasting in High
               Dimensions",
  publisher = "Springer International Publishing",
  address   = "Cham",
  pages     = "297--317",
  series    = "Lecture notes in statistics",
  year      =  2015,
  url       = "http://dx.doi.org/10.1007/978-3-319-18732-7_15",
  doi       = "10.1007/978-3-319-18732-7\_15",
  language  = "en"
}

@INPROCEEDINGS{Ben-Taieb2019-yx,
  title     = "Regularized regression for hierarchical forecasting without
               unbiasedness conditions",
  author    = "Ben Taieb, Souhaib and Koo, Bonsoo",
  booktitle = "Proceedings of the 25th ACM SIGKDD International Conference on
               Knowledge Discovery \& Data Mining",
  publisher = "ACM",
  address   = "New York, NY, USA",
  month     =  "25~" # jul,
  year      =  2019,
  url       = "http://dx.doi.org/10.1145/3292500.3330976",
  doi       = "10.1145/3292500.3330976"
}

@ARTICLE{Bandara2022-og,
  title         = "{MSTL}: A seasonal-Trend decomposition algorithm for time
                   series with Multiple Seasonal patterns",
  author        = "Bandara, Kasun and Hyndman, Rob J and Bergmeir, Christoph",
  journal       = "arXiv [stat.AP]",
  abstract      = "The decomposition of time series into components is an
                   important task that helps to understand time series and can
                   enable better forecasting. Nowadays, with high sampling rates
                   leading to high-frequency data (such as daily, hourly, or
                   minutely data), many real-world datasets contain time series
                   data that can exhibit multiple seasonal patterns. Although
                   several methods have been proposed to decompose time series
                   better under these circumstances, they are often
                   computationally inefficient or inaccurate. In this study, we
                   propose Multiple Seasonal-Trend decomposition using Loess
                   (MSTL), an extension to the traditional Seasonal-Trend
                   decomposition using Loess (STL) procedure, allowing the
                   decomposition of time series with multiple seasonal patterns.
                   In our evaluation on synthetic and a perturbed real-world
                   time series dataset, compared to other decomposition
                   benchmarks, MSTL demonstrates competitive results with lower
                   computational cost. The implementation of MSTL is available
                   in the R package forecast.",
  year          =  2022,
  url           = "http://arxiv.org/abs/2107.13462",
  archivePrefix = "arXiv",
  primaryClass  = "stat.AP"
}

@ARTICLE{Wickramasuriya2021-jh,
  title         = "Probabilistic forecast reconciliation under the Gaussian
                   framework",
  author        = "Wickramasuriya, Shanika L",
  journal       = "arXiv [stat.ME]",
  abstract      = "Forecast reconciliation of multivariate time series is the
                   process of mapping a set of incoherent forecasts into
                   coherent forecasts to satisfy a given set of linear
                   constraints. Commonly used projection matrix based approaches
                   for point forecast reconciliation are OLS (ordinary least
                   squares), WLS (weighted least squares), and MinT (minimum
                   trace). Even though point forecast reconciliation is a
                   well-established field of research, the literature on
                   generating probabilistic forecasts subject to linear
                   constraints is somewhat limited. Available methods follow a
                   two-step procedure. Firstly, it draws future sample paths
                   from the univariate models fitted to each series in the
                   collection (which are incoherent). Secondly, it uses a
                   projection matrix based approach or empirical copula based
                   reordering approach to account for contemporaneous
                   correlations and linear constraints. The projection matrices
                   are estimated either by optimizing a scoring rule such as
                   energy or variogram score, or simply using a projection
                   matrix derived for point forecast reconciliation. This paper
                   proves that (a) if the incoherent predictive distribution is
                   Gaussian then MinT minimizes the logarithmic scoring rule;
                   and (b) the logarithmic score of MinT for each marginal
                   predictive density is smaller than that of OLS. We show these
                   theoretical results using a set of simulation studies. We
                   also evaluate them using the Australian domestic tourism data
                   set.",
  month         =  "20~" # mar,
  year          =  2021,
  url           = "http://arxiv.org/abs/2103.11128",
  archivePrefix = "arXiv",
  primaryClass  = "stat.ME"
}

@INCOLLECTION{Carrara2025-rz,
  title     = "A novel shrinkage estimator of the covariance matrix for
               hierarchical time series",
  author    = "Carrara, Chiara and Zambon, Lorenzo and Azzimonti, Dario and
               Corani, Giorgio",
  booktitle = "Italian Statistical Society Series on Advances in Statistics",
  publisher = "Springer Nature Switzerland",
  address   = "Cham",
  pages     = "140--145",
  year      =  2025,
  url       = "http://dx.doi.org/10.1007/978-3-031-96736-8_24",
  doi       = "10.1007/978-3-031-96736-8\_24",
  language  = "en"
}

@ARTICLE{Spiliotis2021-hg,
  title         = "Hierarchical forecast reconciliation with machine learning",
  author        = "Spiliotis, Evangelos and Abolghasemi, Mahdi and Hyndman, Rob
                   J and Petropoulos, Fotios and Assimakopoulos, Vassilios",
  journal       = "arXiv [cs.LG]",
  abstract      = "Hierarchical forecasting methods have been widely used to
                   support aligned decision-making by providing coherent
                   forecasts at different aggregation levels. Traditional
                   hierarchical forecasting approaches, such as the bottom-up
                   and top-down methods, focus on a particular aggregation level
                   to anchor the forecasts. During the past decades, these have
                   been replaced by a variety of linear combination approaches
                   that exploit information from the complete hierarchy to
                   produce more accurate forecasts. However, the performance of
                   these combination methods depends on the particularities of
                   the examined series and their relationships. This paper
                   proposes a novel hierarchical forecasting approach based on
                   machine learning that deals with these limitations in three
                   important ways. First, the proposed method allows for a
                   non-linear combination of the base forecasts, thus being more
                   general than the linear approaches. Second, it structurally
                   combines the objectives of improved post-sample empirical
                   forecasting accuracy and coherence. Finally, due to its
                   non-linear nature, our approach selectively combines the base
                   forecasts in a direct and automated way without requiring
                   that the complete information must be used for producing
                   reconciled forecasts for each series and level. The proposed
                   method is evaluated both in terms of accuracy and bias using
                   two different data sets coming from the tourism and retail
                   industries. Our results suggest that the proposed method
                   gives superior point forecasts than existing approaches,
                   especially when the series comprising the hierarchy are not
                   characterized by the same patterns.",
  year          =  2021,
  url           = "https://www.sciencedirect.com/science/article/pii/S1568494621006773",
  archivePrefix = "arXiv",
  primaryClass  = "cs.LG"
}

@ARTICLE{Vaswani2017-gm,
  title         = "Attention is all you need",
  author        = "Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and
                   Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and
                   Kaiser, Lukasz and Polosukhin, Illia",
  journal       = "arXiv [cs.CL]",
  abstract      = "The dominant sequence transduction models are based on
                   complex recurrent or convolutional neural networks in an
                   encoder-decoder configuration. The best performing models
                   also connect the encoder and decoder through an attention
                   mechanism. We propose a new simple network architecture, the
                   Transformer, based solely on attention mechanisms, dispensing
                   with recurrence and convolutions entirely. Experiments on two
                   machine translation tasks show these models to be superior in
                   quality while being more parallelizable and requiring
                   significantly less time to train. Our model achieves 28.4
                   BLEU on the WMT 2014 English-to-German translation task,
                   improving over the existing best results, including ensembles
                   by over 2 BLEU. On the WMT 2014 English-to-French translation
                   task, our model establishes a new single-model
                   state-of-the-art BLEU score of 41.8 after training for 3.5
                   days on eight GPUs, a small fraction of the training costs of
                   the best models from the literature. We show that the
                   Transformer generalizes well to other tasks by applying it
                   successfully to English constituency parsing both with large
                   and limited training data.",
  month         =  "12~" # jun,
  year          =  2017,
  url           = "http://arxiv.org/abs/1706.03762",
  archivePrefix = "arXiv",
  primaryClass  = "cs.CL"
}

@ARTICLE{Wickramasuriya2024-mb,
  title     = "Probabilistic forecast reconciliation under the Gaussian
               framework",
  author    = "Wickramasuriya, Shanika L",
  journal   = "Journal of business \& economic statistics: a publication of the
               American Statistical Association",
  publisher = "Informa UK Limited",
  volume    =  42,
  number    =  1,
  pages     = "272--285",
  month     =  "2~" # jan,
  year      =  2024,
  url       = "http://dx.doi.org/10.1080/07350015.2023.2181176",
  doi       = "10.1080/07350015.2023.2181176",
  language  = "en"
}

@MISC{O-Hara-Wild2024-we,
  title    = "Fabletools {R} package",
  author   = "O'Hara-Wild, M and Hyndman, R J and Wang, E",
  abstract = "Provides tools, helpers and data structures for developing models
              and time series functions for fable and extension packages. These
              tools support a consistent and tidy interface for time series
              modelling and analysis.",
  year     =  2024,
  url      = "https://fabletools.tidyverts.org/",
  language = "en",
  version  = "v0.5.0"
}

@MISC{tourism-au,
  title        = "Tourism Research Australia",
  abstract     = "Tourism Research Australia (TRA) is Australia's leading
                  provider of quality tourism intelligence across both
                  international and domestic markets, providing statistics and
                  research to assist the government, the visitor economy and
                  Australian businesses.",
  year         =  2024,
  howpublished = "\url{https://www.tra.gov.au/}",
  note         = "Accessed: 2025-5-9",
  keywords     = "Data",
  language     = "en"
}

@ARTICLE{Ledoit2003-qv,
  title     = "Improved estimation of the covariance matrix of stock returns
               with an application to portfolio selection",
  author    = "Ledoit, Olivier and Wolf, Michael",
  journal   = "Journal of empirical finance",
  publisher = "Elsevier BV",
  volume    =  10,
  number    =  5,
  pages     = "603--621",
  abstract  = "This paper proposes to estimate the covariance matrix of stock
               returns by an optimally weighted average of two existing
               estimators: the sample covariance matrix and single-index
               covariance matrix. This method is generally known as shrinkage,
               and it is standard in decision theory and in empirical Bayesian
               statistics. Our shrinkage estimator can be seen as a way to
               account for extra-market covariance without having to specify an
               arbitrary multifactor structure. For NYSE and AMEX stock returns
               from 1972 to 1995, it can be used to select portfolios with
               significantly lower out-of-sample variance than a set of existing
               estimators, including multifactor models.",
  month     =  dec,
  year      =  2003,
  url       = "http://dx.doi.org/10.1016/s0927-5398(03)00007-0",
  doi       = "10.1016/s0927-5398(03)00007-0",
  language  = "en"
}

@ARTICLE{Hyndman2016-ic,
  title     = "Fast computation of reconciled forecasts for hierarchical and
               grouped time series",
  author    = "Hyndman, Rob J and Lee, Alan J and Wang, Earo",
  journal   = "Computational statistics \& data analysis",
  publisher = "Elsevier BV",
  volume    =  97,
  pages     = "16--32",
  abstract  = "It is shown that the least squares approach to reconciling
               hierarchical time series forecasts can be extended to much more
               general collections of time series with aggregation constraints.
               The constraints arise due to the need for forecasts of
               collections of time series to add up in the same way as the
               observed time series. It is also shown that the computations
               involved can be handled efficiently by exploiting the structure
               of the associated design matrix, or by using sparse matrix
               routines. The proposed algorithms make forecast reconciliation
               feasible in business applications involving very large numbers of
               time series.",
  month     =  may,
  year      =  2016,
  url       = "http://dx.doi.org/10.1016/j.csda.2015.11.007",
  doi       = "10.1016/j.csda.2015.11.007",
  language  = "en"
}

@ARTICLE{Hyndman2011-jv,
  title     = "Optimal combination forecasts for hierarchical time series",
  author    = "Hyndman, Rob J and Ahmed, Roman A and Athanasopoulos, George and
               Shang, Han Lin",
  journal   = "Computational statistics \& data analysis",
  publisher = "Elsevier BV",
  volume    =  55,
  number    =  9,
  pages     = "2579--2589",
  abstract  = "In many applications, there are multiple time series that are
               hierarchically organized and can be aggregated at several
               different levels in groups based on products, geography or some
               other features. We call these “hierarchical time series”. They
               are commonly forecast using either a “bottom-up” or a “top-down”
               method.In this paper we propose a new approach to hierarchical
               forecasting which provides optimal forecasts that are better than
               forecasts produced by either a top-down or a bottom-up approach.
               Our method is based on independently forecasting all series at
               all levels of the hierarchy and then using a regression model to
               optimally combine and reconcile these forecasts. The resulting
               revised forecasts add up appropriately across the hierarchy, are
               unbiased and have minimum variance amongst all combination
               forecasts under some simple assumptions.We show in a simulation
               study that our method performs well compared to the top-down
               approach and the bottom-up method. We demonstrate our proposed
               method by forecasting Australian tourism demand where the data
               are disaggregated by purpose of travel and geographical region.",
  month     =  sep,
  year      =  2011,
  url       = "http://dx.doi.org/10.1016/j.csda.2011.03.006",
  doi       = "10.1016/j.csda.2011.03.006",
  language  = "en"
}

@ARTICLE{Higham2002-te,
  title     = "Computing the nearest correlation matrix—a problem from finance",
  author    = "Higham, N",
  journal   = "Ima Journal of Numerical Analysis",
  publisher = "ieeexplore.ieee.org",
  volume    =  22,
  pages     = "329--343",
  abstract  = "Given a symmetric matrix what is the nearest correlation matrix,
               that is, the nearest symmetric positive semidefinite matrix with
               unit diagonal? This problem arises in the finance industry, where
               the correlations are between stocks. For distance measured in two
               weighted Frobenius norms we characterize the solution using
               convex analysis. We show how the modified alternating projections
               method can be used to compute the solution for the more commonly
               used of the weighted Frobenius norms. In the finance application
               the original matrix has many zero or negative eigenvalues; we
               show that for a certain class of weights the nearest correlation
               matrix has correspondingly many zero eigenvalues and that this
               fact can be exploited in the computation.",
  month     =  "1~" # jul,
  year      =  2002,
  url       = "http://dx.doi.org/10.1093/IMANUM/22.3.329",
  doi       = "10.1093/IMANUM/22.3.329"
}

@MISC{WickramasuriyaUnknown-yf,
  title  = "Synopsis - Honours Thesis",
  author = "Wickramasuriya, Shanika and Athanasopoulos, George"
}

@ARTICLE{Wickramasuriya2021-ly,
  title         = "Properties of point forecast reconciliation approaches",
  author        = "Wickramasuriya, Shanika L",
  journal       = "arXiv [stat.ME]",
  abstract      = "Point forecast reconciliation of collection of time series
                   with linear aggregation constraints has evolved substantially
                   over the last decade. A few commonly used methods are GLS
                   (generalized least squares), OLS (ordinary least squares),
                   WLS (weighted least squares), and MinT (minimum trace). GLS
                   and MinT have similar mathematical expressions, but they
                   differ by the covariance matrix used. OLS and WLS can be
                   considered as special cases of MinT where they differ by the
                   assumptions made about the structure of the covariance
                   matrix. All these methods ensure that the reconciled
                   forecasts are unbiased, provided that the base forecasts are
                   unbiased. The ERM (empirical risk minimizer) approach was
                   proposed to relax the assumption of unbiasedness. This paper
                   proves that (a) GLS and MinT reduce to the same solution; (b)
                   on average, a method similar to ERM (which we refer to as
                   MinT-U) can produce better forecasts than MinT (lowest total
                   mean squared error) which is then followed by OLS and then by
                   base; and (c) the mean squared error of each series in the
                   structure for MinT-U is smaller than that for MinT which is
                   then followed by that for either OLS or base forecasts. We
                   show these theoretical results using a set of simulation
                   studies. We also evaluate them using the Australian domestic
                   tourism data set.",
  month         =  "20~" # mar,
  year          =  2021,
  url           = "http://arxiv.org/abs/2103.11129",
  archivePrefix = "arXiv",
  primaryClass  = "stat.ME"
}

@ARTICLE{Athanasopoulos2024-as,
  title     = "Forecast reconciliation: A review",
  author    = "Athanasopoulos, George and Hyndman, Rob J and Kourentzes,
               Nikolaos and Panagiotelis, Anastasios",
  publisher = "Elsevier",
  volume    =  40,
  number    =  2,
  pages     = "430--456",
  abstract  = "Collections of time series formed via aggregation are prevalent
               in many fields. These are commonly referred to as hierarchical
               time series and may be constructed cross-sectionally across
               different variables, temporally by aggregating a single series at
               different frequencies, or even generalised beyond aggregation as
               time series that respect linear constraints. When forecasting
               such time series, a desirable condition is for forecasts to be
               coherent: to respect the constraints. The past decades have seen
               substantial growth in this field with the development of
               reconciliation methods that ensure coherent forecasts and improve
               forecast accuracy. This paper serves as a comprehensive review of
               forecast reconciliation and an entry point for researchers and
               practitioners dealing with hierarchical time series. The scope of
               the article includes perspectives on forecast reconciliation from
               machine learning, Bayesian statistics and …",
  month     =  "1~" # apr,
  year      =  2024,
  url       = "https://www.sciencedirect.com/science/article/pii/S0169207023001097"
}

@ARTICLE{Wickramasuriya2020-uk,
  title     = "Optimal non-negative forecast reconciliation",
  author    = "Wickramasuriya, Shanika L and Turlach, Berwin A and Hyndman, Rob
               J",
  journal   = "Statistics and computing",
  publisher = "Springer Science and Business Media LLC",
  volume    =  30,
  number    =  5,
  pages     = "1167--1182",
  month     =  sep,
  year      =  2020,
  url       = "http://dx.doi.org/10.1007/s11222-020-09930-0",
  doi       = "10.1007/s11222-020-09930-0",
  language  = "en"
}

@ARTICLE{Panagiotelis2023-fs,
  title     = "Probabilistic forecast reconciliation: Properties, evaluation and
               score optimisation",
  author    = "Panagiotelis, Anastasios and Gamakumara, Puwasala and
               Athanasopoulos, George and Hyndman, Rob J",
  journal   = "European journal of operational research",
  publisher = "Elsevier BV",
  volume    =  306,
  number    =  2,
  pages     = "693--706",
  month     =  apr,
  year      =  2023,
  url       = "http://dx.doi.org/10.1016/j.ejor.2022.07.040",
  doi       = "10.1016/j.ejor.2022.07.040",
  language  = "en"
}

@ARTICLE{Luo2011-my,
  title         = "Recovering model structures from large low rank and sparse
                   covariance matrix estimation",
  author        = "Luo, Xi",
  journal       = "arXiv [stat.ME]",
  abstract      = "Many popular statistical models, such as factor and random
                   effects models, give arise a certain type of covariance
                   structures that is a summation of low rank and sparse
                   matrices. This paper introduces a penalized approximation
                   framework to recover such model structures from large
                   covariance matrix estimation. We propose an estimator based
                   on minimizing a non-likelihood loss with separable non-smooth
                   penalty functions. This estimator is shown to recover exactly
                   the rank and sparsity patterns of these two components, and
                   thus partially recovers the model structures. Convergence
                   rates under various matrix norms are also presented. To
                   compute this estimator, we further develop a first-order
                   iterative algorithm to solve a convex optimization problem
                   that contains separa- ble non-smooth functions, and the
                   algorithm is shown to produce a solution within
                   O(1/t\textasciicircum2) of the optimal, after any finite t
                   iterations. Numerical performance is illustrated using
                   simulated data and stock portfolio selection on S\&P 100.",
  month         =  "4~" # nov,
  year          =  2011,
  url           = "https://www.researchgate.net/profile/Xi-Luo-17/publication/51952042_High_Dimensional_Low_Rank_and_Sparse_Covariance_Matrix_Estimation_viaConvex_Minimization/links/00b4952127dbaebd4b000000/High-Dimensional-Low-Rank-and-Sparse-Covariance-Matrix-Estimation-via-Convex-Minimization.pdf",
  archivePrefix = "arXiv",
  primaryClass  = "stat.ME"
}

@ARTICLE{Hardin2013-wu,
  title     = "A method for generating realistic correlation matrices",
  author    = "Hardin, Johanna and Garcia, Stephan Ramon and Golan, David",
  journal   = "The annals of applied statistics",
  publisher = "Institute of Mathematical Statistics",
  volume    =  7,
  number    =  3,
  pages     = "1733--1762",
  year      =  2013,
  url       = "https://www.jstor.org/stable/23566492",
  keywords  = "Simulation"
}

@ARTICLE{Fan2013-jz,
  title     = "Large covariance estimation by thresholding principal orthogonal
               complements",
  author    = "Fan, Jianqing and Liao, Yuan and Mincheva, Martina",
  journal   = "Journal of the Royal Statistical Society. Series B, Statistical
               methodology",
  publisher = "Oxford University Press (OUP)",
  volume    =  75,
  number    =  4,
  pages     = "603--680",
  abstract  = "This paper deals with the estimation of a high-dimensional
               covariance with a conditional sparsity structure and
               fast-diverging eigenvalues. By assuming sparse error covariance
               matrix in an approximate factor model, we allow for the presence
               of some cross-sectional correlation even after taking out common
               but unobservable factors. We introduce the Principal Orthogonal
               complEment Thresholding (POET) method to explore such an
               approximate factor structure with sparsity. The POET estimator
               includes the sample covariance matrix, the factor-based
               covariance matrix (Fan, Fan, and Lv, 2008), the thresholding
               estimator (Bickel and Levina, 2008) and the adaptive thresholding
               estimator (Cai and Liu, 2011) as specific examples. We provide
               mathematical insights when the factor analysis is approximately
               the same as the principal component analysis for high-dimensional
               data. The rates of convergence of the sparse residual covariance
               matrix and the conditional sparse covariance matrix are studied
               under various norms. It is shown that the impact of estimating
               the unknown factors vanishes as the dimensionality increases. The
               uniform rates of convergence for the unobserved factors and their
               factor loadings are derived. The asymptotic results are also
               verified by extensive simulation studies. Finally, a real data
               application on portfolio allocation is presented.",
  month     =  "1~" # sep,
  year      =  2013,
  url       = "https://academic.oup.com/jrsssb/article-abstract/75/4/603/7075932",
  keywords  = "High-dimensionality; approximate factor model; cross-sectional
               correlation; diverging eigenvalues; low-rank matrix; principal
               components; sparse matrix; thresholding; unknown factors",
  doi       = "10.1111/rssb.12016",
  language  = "en"
}

@ARTICLE{Schafer2005-yw,
  title     = "A shrinkage approach to large-scale covariance matrix estimation
               and implications for functional genomics",
  author    = "Schäfer, Juliane and Strimmer, Korbinian",
  journal   = "Statistical applications in genetics and molecular biology",
  publisher = "Walter de Gruyter GmbH",
  volume    =  4,
  number    =  1,
  pages     = "Article32",
  abstract  = "Inferring large-scale covariance matrices from sparse genomic
               data is an ubiquitous problem in bioinformatics. Clearly, the
               widely used standard covariance and correlation estimators are
               ill-suited for this purpose. As statistically efficient and
               computationally fast alternative we propose a novel shrinkage
               covariance estimator that exploits the Ledoit-Wolf (2003) lemma
               for analytic calculation of the optimal shrinkage intensity.
               Subsequently, we apply this improved covariance estimator (which
               has guaranteed minimum mean squared error, is well-conditioned,
               and is always positive definite even for small sample sizes) to
               the problem of inferring large-scale gene association networks.
               We show that it performs very favorably compared to competing
               approaches both in simulations as well as in application to real
               expression data.",
  month     =  "14~" # nov,
  year      =  2005,
  url       = "https://www.degruyter.com/document/doi/10.2202/1544-6115.1175/html",
  doi       = "10.2202/1544-6115.1175",
  language  = "en"
}

@ARTICLE{Wickramasuriya2019-xq,
  title     = "Optimal forecast reconciliation for hierarchical and grouped time
               series through trace minimization",
  author    = "Wickramasuriya, Shanika L and Athanasopoulos, George and Hyndman,
               Rob J",
  journal   = "Journal of the American Statistical Association",
  publisher = "Informa UK Limited",
  volume    =  114,
  number    =  526,
  pages     = "804--819",
  month     =  "3~" # apr,
  year      =  2019,
  url       = "http://dx.doi.org/10.1080/01621459.2018.1448825",
  doi       = "10.1080/01621459.2018.1448825",
  language  = "en"
}

@ARTICLE{Huang2019-ua,
  title     = "{NOVELIST} estimator of large correlation and covariance matrices
               and their inverses",
  author    = "Huang, Na and Fryzlewicz, Piotr",
  journal   = "Test (Madrid, Spain)",
  publisher = "Springer Science and Business Media LLC",
  volume    =  28,
  number    =  3,
  pages     = "694--727",
  month     =  sep,
  year      =  2019,
  url       = "http://dx.doi.org/10.1007/s11749-018-0592-4",
  doi       = "10.1007/s11749-018-0592-4",
  language  = "en"
}
